\documentclass[12pt, titlepage]{report}
\usepackage{consumer_resource_final}
\graphicspath{{./figures/}}

\begin{document}
As stated in the introduction, we are interested in the equilibria points of the set of coupled differential equations \eqref{eq : differential eq for resources and species}. In particular we want to know how \important{stable} a given equilibrium is. However the notion of \important{stability} itself is not trivial : what does it mean exactly that a system is stable under a given perturbation? How is a perturbation even defined? These questions have many different possible answers. Throughout this thesis different notions of stability will be tackled : the first is \important{dynamical stability}.

The main idea behind dynamical stability is simple. We want to answer the following question :

\begin{centering}
\fbox{\begin{minipage}{\linewidth}
Given an equilibrium point $\{ R^*_\mu, S^*_i\}$, does the system go back to a positive-valued equilibrium when the consumers and resources abundances are changed? If yes, how much can they be changed before the system evolves in such a way that it does not reach a positive-valued equilibrium?
\end{minipage}}
\end{centering}
\subsection{Definitions}
\subsubsection{Local dynamical stability}
The first notion to introduce is \define{local dynamical stability} : a system is said to be \important{locally dynamically stable} if it goes back to \important{its initial equilibrium point} $\{ R^*_\mu, S^*_i \} $ after $R^*_\mu$ and $S^*_i$ have been perturbed by an infinitesimal amount $\{ \Delta R_\mu, \Delta S_i \}$.
Because the perturbations are supposed to be very small, we can write :
\begin{equation}
\begin{pmatrix}
\frac{dR_\mu(t)}{dt} \\
\frac{dS_i(t)}{dt}
\end{pmatrix}
=
\begin{pmatrix}
\frac{d\Delta R_\mu(t)}{dt} \\
\frac{d\Delta S_i(t)}{dt}
\end{pmatrix}
=
J
\begin{pmatrix}
\Delta R_\mu(t) \\
\Delta S_i(t)
\end{pmatrix}
\end{equation}
where $J$ is the \define{jacobian} of our system \ie the jacobian matrix of its temporal evolution \eqref{eq : differential eq for resources and species}:
\begin{equation}
  J \defined
\begin{pmatrix}
  \partiald{\dot{R_\mu}}{R_\nu}& \partiald{\dot{R_\mu}}{S_j} \\
  \partiald{\dot{S_i}}{R_\nu} & \partiald{\dot{S_i}}{S_j}
\end{pmatrix}
=
\begin{pmatrix}
  \left(-m_\mu-\sum_j \gamma_{j\mu}S_j\right)\delta_{\mu\nu} & -\gamma_{j\mu}R_\mu+\alpha_{\mu j} \\
  \sigma_{i\nu}\gamma_{i\nu}S_i &\left(\sum_{\nu} \sigma_{i\nu}\gamma_{i\nu}R_\nu-d_i-\sum_\nu \alpha_{\nu i}\right)\delta_{ij}
\end{pmatrix}, \label{eq : definition of jacobian}
\end{equation}
where $\delta$ is the Kronecker delta symbol. Using the fact that we are only interested in equilibria where every resource is positive and Eq.\eqref{eq : equilibrium species}, this can be rewritten as :
\begin{equation}
 J = \begin{pmatrix}
   \frac{l_\mu + \sum_j \alpha_{\mu j}S_j^*}{R^*_\mu}\delta_{\mu\nu} & -\gamma_{j\mu}R_\mu+\alpha_{\mu j} \\
   \sigma_{i\nu}\gamma_{i\nu}S_i &\left(\sum_{\nu} \sigma_{i\nu}\gamma_{i\nu}R_\nu-d_i-\sum_\nu \alpha_{\nu i}\right)\delta_{ij}
 \end{pmatrix}, \label{eq : definition of jacobian alternative}
\end{equation}
We can then define for a given equilibrium point $\{R^*_\mu, S^*_i\}$ the \define{jacobian at equilibrium} $J^*$ as the jacobian of said equilibrium.
We will hence say that a given equilibrium is \textit{locally dynamically stable} if its jacobian $J^*$ is negative definite, \ie if the largest real part of the eigenvalues of $J^*$ is negative.

Note that since we are interested only in positive valued equilibria (\ie $S^*_i > 0 \ \forall i$), then Eq.\eqref{eq : equilibrium species} is equivalent to :
\begin{equation}
  \sum_\nu \sigma_{i\nu} \gamma_{i\nu}R^*_\nu -d_i - \sum_\nu \alpha_{\nu i} = 0,
\end{equation}
which means that the lower right block of the jacobian in Eq.\eqref{eq : definition of jacobian} will be zero. Hence at equilibrium the jacobian $J^*$ will have the following block form:
\begin{equation}
  J^* = \begin{pmatrix}
  -\Delta & \Gamma \\
  \Beta & 0
\end{pmatrix}, \label{eq : jacobian at equilibrium}
\end{equation}
where

\begin{centering}
\fbox{\begin{minipage}{\linewidth}
\begin{itemize}
  \item $\Delta_{\mu\nu} = \text{diag}(m_\mu+\sum_j \gamma_{j\mu} S^*_j) = \text{diag}\left(\frac{l_\mu + \sum_j \alpha_{\mu j}S_j^*}{R^*_\mu}\right)$ is a positive $N_R \times N_R$ diagonal matrix,
  \item $\Gamma_{\mu j} = -\gamma_{j\mu}R^*_\mu + \alpha_{\mu j}$ is a $N_R \times N_S$ matrix which does not have entries with a definite sign.
  \item $\Beta_{i\nu} = \sigma_{i\nu} \gamma_{i\nu} S^*_i$ is a $N_S \times N_R$ matrix with positive entries.
\end{itemize}
\end{minipage}}
\end{centering}

\subsubsection{The locally dynamically stable volume $\mathcal{D}^{G,A}_{L,x}$}
Similarly to what was conducted in Methods \ref{sec : methods feasibility}, one can define the \define{parameters set local dynamical stability function} $\mathfrak{D}_L : \mathcal{P} \rightarrow \{
0,1\}$, which tells you whether a given set of parameters $p \in \mathcal{P}$ is locally dynamically stable or not :
\begin{equation}
\mathfrak{D}_L(p)\defined\begin{cases}
1 \text{ if } p \text{ is locally dynamically stable} \\
0 \text{ else.}
\end{cases}
\end{equation}
Note that trivially $p$ has to be feasible in order to be locally dynamically stable :
\begin{equation}
\mathfrak{D}_L(p)=1 \implies \mathfrak{F}(p)=1. \label{eq : locally dynamically stable implies feasible}
\end{equation}
Again, we also define the \define{metaparameters set local dynamical stability function} $\mathcal{D}_L : \mathcal{M} \times \mathcal{B}_{N_S \times N_R} \times \mathcal{B}_{N_R \times N_S} \rightarrow [0,1]$ which tells you, given a set of metaparamters $m \in \mathcal{M}$ and a consumption-syntrophy network $B=(G,A)$ the chance that you draw a locally dynamically stable set of parameters :
\begin{equation}
\boxed{\mathcal{D}_L(m, B)\defined\text{Probability}\left\{\mathfrak{D}_L(\mathcal{A}(m, B))=1\right\}}.
\end{equation}
We also define the $x$ locally dynamically stable (lds) volume $\mathcal{D}_{L,x}^{G,A}$ by the region of the metaparameters space that gives rise to a percentage of $x$ dynamically stable systems:
\begin{equation}
\mathcal{D}_{L,x}^{G,A} \defined \left\{m \in \mathcal{M} : \mathcal{D}_L(m, (G,A)) \geq x \right\}
\end{equation}
Clearly, $\mathcal{D}_{L,0}^{G,A}=\mathcal{M}$, $\text{Vol}\left(\mathcal{D}_{L,x}^{G,A}\right) \leq \text{Vol}\left(\mathcal{D}_{L,y}^{G,A}\right)$ $\forall x \geq y$, and more importantly, Eq.\eqref{eq : locally dynamically stable implies feasible} is equivalent to $\mathcal{D}_{L,x}^{G,A} \subset \mathcal{V}_x^{G,A}$. We can also define for a set of $N$ couples of matrices $S=\left\{(G_1, A_1) \dots, (G_N, A_N)\right\}$ their common $x$ (lds) volume $\mathcal{D}_{L,x}^S$ :
\begin{equation}
\mathcal{D}_{L,x}^S \defined \intersection{(G,A) \in S} \mathcal{D}_{L,x}^{G,A}.
\end{equation}
For such a set $S$ we define also its critical local dynamical stability $d_L^*(S)$ which is the largest local dynamical stability we can get while still having a non-zero common volume :
\begin{equation}
d_L^*(S) = \max_{x \in [0,1]}\left\{x : \text{Vol}(D_{L,x}) > 0\right\}.
\end{equation}
Finally the critical common local dynamical stability volume $\mathcal{D}^S_{L}$ is the common lds volume at critical lds :
\begin{equation}
\mathcal{D}^*_L \defined \mathcal{D}_{L, d_L^*(S)}^S.
\end{equation}

\subsubsection{Global dynamical stability}
If we established that a system is locally dynamically stable, we know that it will come back to the same equilibrium after an infinitesimal perturbation of the resources and consumers abundances. The next natural question is : \important{how much} can these be perturbed before the system goes to a point where either at least a species has gone extinct or reaches another positive valued equilibrium $\{ \tilde{R}^*_\mu, \tilde{S}^*_i\}$ or simply does not reach a new dynamical equilibrium?
One way of studying this \cite{pascual-garcia_mutualism_2017} is to simply take an equilibrium point $\{ R^*_\mu, S^*_i\}$ and perturb the abundance of the species and resources at that point by a fixed number $\Delta_D \in \left[0, 1\right]$ which allows us to quantify the perturbation:
\begin{empheq}[left=\empheqlbrace]{align}
  R^*_\mu \rightarrow R_\mu(t_0) \equiv  R^*_\mu \left(1+\Delta_D \nu_\mu\right), \\
  S^*_i \rightarrow S_\mu(t_0) \equiv S^*_i \left(1+\Delta_D \nu_i \right),
\end{empheq}
where the $\nu_{\mu, i}$ are random numbers drawn from a uniform distribution between -1 and +1 and $t_0$ is the time where the previously at equilibrium system is perturbed. This is basically the same procedure as local dynamical stability except we allow the perturbation $\Delta_D$ to be non-zero. The question we will often ask is precisely how big can $\Delta_D$ be.
The system with the initial values $\{R(t_0), S(t_0)\}$ can then be time evolved from $t=t_0$ until it reaches an equilibrium $\{\tilde{R}^{*}, \tilde{S}^{*}\}$ which may be different from the equilibrium $\{R^*, S^*\}$ initially considered.

A certain number of quantities, that all depend on the perturbation $\Delta_D$, can then be measured to quantify the dynamical stability of the system :
\begin{itemize}
  \item The resilience $t_R$: this is the time scale over which the system reaches its new equilibrium.
  \item The number of extinctions $E$ : this is the number of species or resources which died during the time it took the system to reach its new equilibrium.
  \item The angle $\alpha$ between two equilibria : this quantifies how close the old and new equilibria are. $\alpha$ is defined through its standard scalar product formula :
  \begin{equation}
  \cos(\alpha) \equiv \frac{\sum_\mu R^*_\mu \tilde{R}^*_\mu + \sum_j S^*_j\tilde{S}^*_j}{\sqrt{\sum_\mu \left(R^*_\mu\right)^2 + \sum_i \left(S^*_i\right)^2}\sqrt{\sum_\mu \left(\tilde{R}^*_\mu\right)^2 + \sum_i \left(\tilde{S}^*_i\right)^2}}.
  \end{equation}
\end{itemize}
These quantities have either been already introduced in previous papers or are natural extensions of standard quantities \cite{ives_stability_2007,pascual-garcia_mutualism_2017}. They allow us to quantify the robustness of a given equilibrium.

\subsection{The quest for a full solution}
The question of global dynamical stability is mathematically tedious, so we start by focusing on local dynamical stability.

Here we aim to find the spectrum of the jacobian at equilibrium, which will tell us whether the system is locally dynamically stable or not (see above).

\subsubsection{How to determine local dynamical stability}
As explained, we need to determine the sign of the largest real part of all the eigenvalues of $J^*$.
More precisely, mathematically we are interested in the real part of $\lambda_1$, which itself is defined by the following property:
\begin{equation}
\forall \lambda \in \sigma(J^*), \ \real{\lambda} \leq \real{\lambda_1},
\end{equation}
where $\sigma(J^*)$ is the set of eigenvalues of $J^*$, called the \define{spectrum} of $J^*$.
The sign of $\lambda_1$, will govern the local stability of the system at equilibrium. Namely \textbf{Need to add resource?} :
\begin{itemize}
\item $\real{\lambda_1} < 0$ : any perturbation on the abundances will be exponentially supressed. The system is stable.
\item $\real{\lambda_1} > 0$ : any perturbation on the abundances will be exponentially amplified. The system is unstable.
\item $\real{\lambda_1}=0$ : a second order perturbation analysis is required to assess the system local stability. We will call such systems \textit{marginally stable} \cite{biroli_marginally_2018}.
\end{itemize}

\subsubsection{The master equation for local dynamical stability}
In order to get $\real{\lambda_1}$, we have to get the full spectrum of $J^*$, as sadly easier standard techniques like the Perron-Frobenius theorem \cite{perron_zur_nodate} cannot be applied. The eigenvalues of $J^*$ are obtained through the eigenvalue problem:
\begin{equation}
\det\left(J^* - \lambda \right) = 0.
\end{equation}
More explicitly, using Eq.\eqref{eq : jacobian at equilibrium}, we state the \important{master equation for local dynamical stability} :
\begin{equation}
\boxed{
\det
\begin{pmatrix}
 -\Delta - \lambda  & \Gamma \\
 \Beta & 0-\lambda
\end{pmatrix} = 0
}\label{eq : master equation eigenvalues jacobian}
\end{equation}
Before proceeding any further, we first eliminate systems where local dynamical stability cannot be decided with the first order perturbation analysis that we are conducting, \ie marginally stable equilibria.

\subsubsection{Marginally stable equilbria}
We want to avoid the case $\real{\lambda_1}=0$, because it is way harder to handle mathematically. To make things easier, we will in our analytical computations\footnote{For numerical computations we will get rid of marginally stable systems individually, meaning we may have some systems where $0 \in \sigma(J^*)$.} get rid of all systems where 0 is part of the spectrum. Even though this is a harsh condition, we know that for such systems, local dynamical stability can be decided by the computations we conduct. $\lambda=0$ is part of the spectrum if and only if it solves the master equation \eqref{eq : master equation eigenvalues jacobian}:
\begin{equation}
\det
\begin{pmatrix}
  -\Delta   & \Gamma \\
  \Beta & 0
\end{pmatrix} = 0 \label{eq : determinant marginally stable equilibria}
\end{equation}
Using the fact that $\Delta$ is invertible, we can make use of the equality\footnote{This uses a formula which is trivially analogous to one found in \cite{powell_calculating_2011}.}:
\begin{equation}
\det\begin{pmatrix}
  -\Delta   & \Gamma \\
  \Beta & 0
\end{pmatrix} = \det(-\Delta)\det(\Gamma\Delta^{-1}\Beta) = (-1)^{N_R}\det(\Gamma\Beta).
\end{equation}
Eq.\eqref{eq : determinant marginally stable equilibria} then becomes :
\begin{equation}
\det(\Gamma\Beta)=\det(\Beta\Gamma)=0
\end{equation}
which means that $\Gamma\Beta$ and $\Beta\Gamma$ are not full rank, \ie $\Gamma$ or $\Beta$ is not full rank.

\subsubsection{Non marginal equilibria}\label{section : non marginal equilibria}
For now we will concentrate on equilibria that are clearly either stable or unstable\footnote{The case of marginally stable systems, where the maximum eigenvalue is zero, will be covered later.}, \ie:
\begin{equation}
\lambda_1 \neq 0.
\end{equation}
For the sake of simplicity, we will first look for the non zero solutions of the spectrum, \ie for now we assume:
\begin{equation}
\lambda \neq 0.
\end{equation}
This immediately implies
\begin{equation}
\det\left(\lambda\right)\neq 0,
\end{equation}
where $\lambda$ actually stands for the $N_S \times N_S$ identity matrix multiplied by a scalar $\lambda$. One can use this condition to simplify Eq.\eqref{eq : master equation eigenvalues jacobian} using the properties of block matrices \cite{powell_calculating_2011} :
\begin{equation}
\det
\begin{pmatrix}
  -\Delta - \lambda  & \Gamma \\
  \Beta & 0-\lambda
\end{pmatrix} =
\det\left(-\lambda\right)\det\left(-\Delta- \lambda+\frac{1}{\lambda}\Gamma \Beta\right).
\end{equation}
Hence Eq.\eqref{eq : master equation eigenvalues jacobian} becomes:
\begin{equation}
\boxed{
\det\left(\lambda^2+\Delta \lambda-\Gamma \Beta\right)=0. \label{eq : master equation non marginal}
}
\end{equation}
The complexity here is already reduced because we go from the determinant of a $N_R+N_S$ square matrix to a $N_R$ square matrix. We see from the previous expression that the dynamics is essentially dictated by the $\Gamma \Beta$ $N_R$-dimensional square matrix, which is given by :
\begin{equation}
\left(\Gamma \Beta\right)_{\mu \nu} = \sum_i \Gamma_{\mu i} \Beta_{i \nu} = \sum_i \left(\alpha_{\mu i}-\gamma_{i \mu} R^*_\mu \right)\sigma_{i\nu}\gamma_{i\nu}S^*_i.
\end{equation}
There are many strategies here to find regimes of stability. One is the so-called ``Reductio ad absurdum'', which is explored later in Methods \ref{subsubsec : reductio ad absurdum}.

\subsection{Bounds on the eigenvalues}
\subsubsection{Gerschgorin's circle theorem}
Gerschgorin's circle theorem \cite{gerschgorin_uber_1931} allows us to get a better idea of the location of the eigenvalues in the complex plane. It states that every eigenvalue of a $N\times N$ square matrix $A$
is located in one of the $N$ discs $D_i$ defined by :
\begin{equation}
D_i\defined \left\{z \in \mathbb{C} : \abs{z-A_{ii}} \leq \sum_{j\neq i} \abs{A_{ij}} \right\}. \label{eq : definition discs Gerschgorin}
\end{equation}
This can be reformulated as :
\begin{equation}
\sigma(A) \subset \union_{i=1}^N D_i. \label{eq : circle theorem}
\end{equation}
The geometrical interpretation is that the eigenvalues of a matrix deviate from the diagonal elements by a value bounded by the sum of the off-diagonal elements.
It is then easy to see that if all the discs $D_i$ are located to the left of the imaginary axis (\ie the discs contain only numbers with a negative real part), then the eigenvalues of $A$ are all negative. Geometrically this corresponds to the following lemma :
\begin{lemma}\label{lemma : lemma Gerschgorin circle}
If for a matrix $A$ the following equations are verified :
\begin{equation}
\real{A_{ii}} + \sum_{j\neq i} \abs{A_{ij}} < 0, \forall \ i, \label{eq : alternative version circle theorem}
\end{equation}
then $\real{\lambda} < 0 \ \forall \lambda \in \sigma(A)$.
\end{lemma}

Gerschgorin's circle theorem allows us to get a precious bound on the modulus of each eigenvalue and hence on the interesting one $\lambda_1$. Indeed we know that all eigenvalues of $J^*$ will be located in one of the discs (as defined in Eq.\eqref{eq : definition discs Gerschgorin}) of $J^*$. There are precisely $N_R + N_S$ discs of $J^*$, these are the ``resources'' discs:
\begin{equation}
D^R_\mu  \defined \left\{ z \in \mathbb{C} : \abs{z+\Delta_\mu} \leq \sum_j \abs{\Gamma_{\mu j}} \right\}  \ \forall \mu = 1, \dots, N_R,
\end{equation}
and the ``consumers'' discs :
\begin{equation}
D^C_i \defined \left\{ z \in \mathbb{C} : \abs{z} \leq \sum_\nu \abs{B_{i\nu}}\right\} \ \forall i=1, \dots, N_S.
\end{equation}
The circle's theorem Eq.\eqref{eq : circle theorem} tells us that all eigenvalues will be in the union of these circles, \ie there exists $\forall \lambda \in \sigma\left(J^*\right)$ at least one $\mu^*$ or  one $i^*$ such that:
\begin{equation}
\abs{\lambda} \leq \sum_\nu \abs{B_{i^*\nu}} \label{eq : bound lambda consumers}
\end{equation}
or
\begin{equation}
\abs{\lambda+\Delta_{\mu^*}} \leq \sum_j \abs{\Gamma_{\mu^* j}} \label{eq : bound lambda 1 resources}
\end{equation}
Note furthermore that, because $\Delta_\mu > 0$ and $\imag{\Delta_\mu}=0$, Eq.\eqref{eq : bound lambda 1 resources} implies
\begin{equation}
\abs{\lambda} \leq \sum_j \abs{\Gamma_{\mu^* j}}. \label{eq : bound lambda resources better}
\end{equation}
The only way both Eq.\eqref{eq : bound lambda consumers} and \eqref{eq : bound lambda resources better} are satisfied for all eigenvalues, and especially the one with the highest real part $\lambda_1$ is if they are bound by the maximum of both RHS of these equations. More precisely :
\begin{equation}
\boxed{
\abs{\lambda} \leq R_C \ \forall \lambda \in \sigma(J^*), \label{eq : overall bound on lambda}
}
\end{equation}
where we defined the critical radius as :
\begin{equation}
R_C \defined \max\left\{\max_i\left\{\sum_\nu \abs{B_{i\nu}}\right\}, \max_\mu\left\{\sum_j \abs{\Gamma_{\mu j}}\right\}\right\}.
\end{equation}
Intuitively, this means every eigenvalue must lie in a circle around the origin. The radius of this circle is given by whichever is larger between the largest column-sums of the $\Beta$ and $\Gamma$ matrices.

\subsubsection{Critical radius in terms of metaparameters}
We would like to estimate $R_C$ in terms of metaparameters, so that we can choose metaparameters that will give rise to systems in an LRI regime, which we know will be dynamically stable.

Using techniques very similar to previous computations :
\begin{equation}
\sum_j \abs{\Gamma_{\mu j}} = \sum_j \abs{\alpha_{\mu j}-\gamma_{j\mu}R^*_\mu} \approx \deg(\Gamma, \mu)\abs{\alpha_0 - \gamma_0 R_0}.
\end{equation}
The difficult part is estimating $\deg(\Gamma, \mu) \approx \deg(A-G^T, \mu)$. If we assume that $\deg(A, \mu)\approx \deg(G^T, \mu) \ll N_S$ then we may use the very loose approximation
\begin{equation}
\deg(A-G^T, \mu) \approx \deg(A, \mu)+\deg(G, \mu).
\end{equation}
In that regime we then have :
\begin{equation}
\max_\mu\left\{\sum_j \abs{\Gamma_{\mu j}}\right\} \approx \max_\mu\left\{\deg(A, \mu)+\deg(G, \mu)\right\} \abs{\alpha_0-\gamma_0 R_0}.
\end{equation}
Similarly we find
\begin{equation}
\sum_\nu \abs{B_{i\nu}} \approx \deg(G, i) \sigma_0 \gamma_0 S_0,
\end{equation}
such that $R_C$ can be estimated roughly as :
\begin{equation}\boxed{
R_C \approx \max\left\{ \max_i\left(\deg(G,i)\right) \sigma_0 \gamma_0 S_0, \max_\mu\left(\deg(A,\mu)+\deg(G,\mu)\right)\abs{\alpha_0-\gamma_0 R_0}\right\}
}\label{eq : estimate R_C metaparameters}
\end{equation}
The main factor that will determine $R_C$ (and hence the largest magnitude of any eigenvalue) is the structure of the food consumption matrix.


\subsection{Low intra resources interaction (LRI) regime }
\subsubsection{Reductio ad absurdum} \label{subsubsec : reductio ad absurdum}
Now that we have a bound on how big the eigenvalues can be, we need to find strategies to find regimes where we \important{know} $\real{\lambda_1} < 0 $, \ie local dynamical stability is guaranteed. We inspire ourselves from the general idea of the mathematical proofs of \cite{butler_stability_2018}.
We first rewrite Eq.\eqref{eq : master equation non marginal} as\footnote{We can do this because since $m_\mu > 0$, we know $\Delta$ will always be invertible.} :
\begin{equation}
\det\left(-\Delta^{-1}\right)\det\left(-\Delta^{-1}\lambda^2-\lambda+\Delta^{-1}\Gamma\Beta\right)=0\iff \boxed{\det\left(S(\lambda)-\lambda\right)=0} \label{eq : eigenvalue problem S}
\end{equation}
with
\begin{equation}
\boxed{S(\lambda)=\Delta^{-1}\Gamma\Beta-\Delta^{-1}\lambda^2}, \label{eq : equation stability S}
\end{equation}
or, component-wise:
\begin{equation}
S_{\mu \nu} = \frac{1}{\Delta_\mu}\left[\left(\sum_i \Gamma_{\mu i}\Beta_{i \nu}\right) - \lambda^2 \delta_{\mu\nu}\right] \label{eq : definition S component wise}
\end{equation}
The idea is to assume we are in an unstable regime, there exists at least $\lambda \in \sigma(J^*)$ which satisfies Eq.\eqref{eq : master equation non marginal} and such that $\real{\lambda} > 0$. By Eq.\eqref{eq : eigenvalue problem S}, $\lambda$ is also an eigenvalue of $S(\lambda)$. If we find conditions under which the real part of the spectrum of $S(\lambda)$ is entirely negative, we will know that $\real{\lambda} \leq 0$. As this is a contradiction to the hypothesis that the regime is unstable, we must conclude that the regime is stable\footnote{Indeed, Eq.\eqref{eq : master equation non marginal} assumes already that either $\real{\lambda_1} >0$ or $\real{\lambda_1} < 0$.}.

Hence, the general strategy is to find regimes where we know that the spectrum of $S$, written as $\sigma(S)$, will be entirely negative for a positive $\lambda$.
\subsubsection{Strong LRI regime}
\begin{theorem}\label{theorem : strong LRI regime}
If a model is not marginally stable at equilibrium and it verifies :
\begin{equation}
\left(\Gamma \Beta\right)_{\mu\mu} < - \sum_{\nu \neq \mu } \abs{\left(\Gamma \Beta\right)_{\mu \nu}} - R_C^2 \ \forall \mu,
\end{equation}
then it is dynamically stable.
\end{theorem}
\begin{proof}
We assume
\begin{equation}
\left(\Gamma \Beta\right)_{\mu\mu} < - \sum_{\nu \neq \mu } \abs{\left(\Gamma \Beta\right)_{\mu \nu}} -R_C^2 \ \forall \mu.
\end{equation}
This implies :
\begin{equation}
\left(\Gamma \Beta\right)_{\mu\mu} + R_C^2< - \sum_{\nu \neq \mu } \abs{\left(\Gamma \Beta\right)_{\mu \nu}} \ \forall \mu.
\end{equation}
Using Eq.\eqref{eq : overall bound on lambda} and $\imag{\lambda}^2 \leq \abs{\lambda}^2$, we get:
\begin{equation}
  \left(\Gamma\Beta \right)_{\mu\mu} + \imag{\lambda}^2 < - \sum_{\nu \neq \mu } \abs{\left(\Gamma \Beta\right)_{\mu \nu}} \ \forall \mu. \label{eq : low species bound 1}
\end{equation}
It is not difficult to prove that for any complex number :
\begin{equation}
\imag{c}^2 \geq - \real{c^2} \ \forall c \in \mathbb{C}.
\end{equation}
Using this result and dividing Eq.\eqref{eq : low species bound 1} by\footnote{This works because $\Delta_\mu > 0$} $\Delta_\mu$, we get :
\begin{equation}
\frac{1}{\Delta_\mu}\left[\left(\sum_i \Gamma_{\mu i} \Beta_{i \mu} \right)-\real{\lambda^2}\right] < - \sum_{\nu \neq \mu } \abs{\frac{\sum_i \Gamma_{\mu i}\Beta_{i\nu}}{\Delta_\mu}} \ \forall \mu.
\end{equation}
Looking at Eq.\eqref{eq : definition S component wise}, we see that this is equivalent to:
\begin{equation}
\real{S_{\mu \mu}} + \sum_{\nu \neq \mu} \abs{S_{\mu \nu}} < 0\ \forall \mu.
\end{equation}
Using Lemma \ref{lemma : lemma Gerschgorin circle}, we know that all the eigenvalues of $S(\lambda)$ will have a negative real part.
As explained before that means that if $\real{\lambda_1} > 0 $ in Eq.\eqref{eq : equation stability S} (unstable regime), then $\real{\lambda_1} < 0$, which leads to a contradiction. This then implies that the equilibrium is dynamically stable.
\end{proof}
\subsubsection{Weak LRI regime}
A weaker version of Theorem \ref{theorem : strong LRI regime} can also be stated.
\begin{theorem}\label{theorem : weak LRI regime}
If a model is not marginally stable at equilibrium and it verifies :
\begin{equation}
\left(\Gamma \Beta\right)_{\mu\mu} < - \sum_{\nu \neq \mu } \abs{\left(\Gamma \Beta\right)_{\mu \nu}} \ \forall \mu,
\end{equation}
then its real eigenvalues are negative.
\end{theorem}
\begin{proof}
We assume
\begin{equation}
\left(\Gamma \Beta\right)_{\mu\mu} < - \sum_{\nu \neq \mu } \abs{\left(\Gamma \Beta\right)_{\mu \nu}}  \ \forall \mu.
\end{equation}
Let $\lambda \in \mathbb{R}$, then the following will also trivially hold:
\begin{equation}
  \left(\Gamma\Beta \right)_{\mu\mu} -\lambda^2 < - \sum_{\nu \neq \mu } \abs{\left(\Gamma \Beta\right)_{\mu \nu}} \ \forall \mu. \label{eq : low species bound 1}
\end{equation}
Dividing Eq.\eqref{eq : low species bound 1} by\footnote{This works because $\Delta_\mu > 0$} $\Delta_\mu$, we get :
\begin{equation}
\frac{1}{\Delta_\mu}\left[\left(\sum_i \Gamma_{\mu i} \Beta_{i \mu} \right)-{\lambda^2}\right] < - \sum_{\nu \neq \mu } \abs{\frac{\sum_i \Gamma_{\mu i}\Beta_{i\nu}}{\Delta_\mu}} \ \forall \mu.
\end{equation}
Looking at Eq.\eqref{eq : definition S component wise}, we see that this is equivalent to:
\begin{equation}
S_{\mu \mu} + \sum_{\nu \neq \mu} \abs{S_{\mu \nu}} < 0\ \forall \mu.
\end{equation}
Using Lemma \ref{lemma : lemma Gerschgorin circle}, we know that all the real eigenvalues of $S(\lambda)$ will have a negative real part.
We can conclude with the statement of the theorem.
\end{proof}



\subsubsection{Feasability of the low intra resources interaction regime}
So we found that if a system has parameters that respect Eq.\eqref{eq : LRI regime} then it is dynamically stable. A naturally arising question is then to ask in what measure this is compatible with the feasability equations Eqs.\eqref{eq: feasability energy conservation}, \eqref{eq : feasability positivity d} and \eqref{eq : feasability positivity m}.

\noindent Finding an approximation of the resource interaction matrix $(\Gamma\Beta)_{\mu \nu}$ using the metaparameters allows to find a necessary condition on the metaparameters. Indeed, using the metaparameters approximations Eq.\eqref{eq : metaparameters approximations}, we get:
\begin{equation}\label{eq : metaparam approximation GammaBeta}
\left(\Gamma \Beta\right)_{\mu \nu}\approx \sigma_0 \gamma_0 S_0 \left(\alpha_0 \sum_i A_{\mu i}G_{i\nu}-\gamma_0 R_0 \sum_i G_{i\mu}G_{i\nu}\right)\defined \sigma_0 \gamma_0 S_0 \left(\alpha_0 O_{\mu \nu}-\gamma_0R_0 C_{\mu\nu}\right)
\end{equation}
where we defined the syntrophy overlap matrix $O_{\mu\nu}$ and the consumption overlap matrix $C_{\mu\nu}$ as :
\begin{equation}
O_{\mu\nu} \defined \left(AG\right)_{\mu \nu} \text{ and } C_{\mu\nu} \defined \left(G^TG\right)_{\mu\nu}.
\end{equation}
The fight syntrophy vs. consumption between these two binary matrices essentially builds the dynamics of our model and an intuition about their meaning can be very helpful.

The syntrophy overlap matrix $O_{\mu\nu}$ is defined as :
\begin{equation}
O_{\mu\nu} \defined \sum_k A_{\mu k} G_{k\nu}.
\end{equation}
Although $A$ and $G$ are binary, $O$ does not have to and usually won't be. A given consumer $k$ contributes to $O_{\mu\nu}$ if and only if both $A_{\mu k}$ and $G_{k\nu}$ are non zero, that is if consumer $k$ releases resource $\mu$ \textit{and} consumes resource $\nu$. Hence $O_{\mu\nu}$ essentially tells how many species effectively link resource $\mu$ to resource $\nu$ through the indirect interaction of the species consumption.

\noindent Similarly, the consumption overlap matrix is defined as :
\begin{equation}
C_{\mu\nu}=\sum_k G_{k \mu}G_{k \nu}.
\end{equation}
Like $O$, $C$ usually will not be binary. The intuition behind $C_{\mu\nu}$ is straight forward: it counts how many species eat both resource $\mu$ and $\nu$. Note that $C_{\mu\nu}=C_{\nu\mu}$ (interesting : hard part comes from the antisymmetric part of S).

We then find a lowerbound for the RHS of Eq.\eqref{eq : LRI regime} :
\begin{equation}
-\sum_{\nu\neq\mu}\abs{\Gamma\Beta}_{\mu\nu} \geq - \sum_{\nu \neq \mu} \max_{\nu \neq \mu} \abs{\Gamma\Beta}_{\mu\nu} \geq - \deg\left(\mu, O-C \right) \max_{\nu \neq \mu} \abs{\Gamma\Beta}_{\mu\nu}.
\end{equation}
Combining this with the approximation of $\Gamma\Beta$ above we get an approximative LRI regime condition on the metaparameters :
\begin{equation}\boxed{
\alpha_0 O_{\mu \mu}-\gamma_0R_0 C_{\mu\mu} \lessapprox - \deg(\mu, O-C) \max_{\nu\neq\mu}\abs{\alpha_0 O_{\mu \nu}-\gamma_0 R_0 C_{\mu\nu}}-\frac{R_C^2}{\sigma_0\gamma_0 S_0} \ \forall \mu.
}\label{eq : LRI metaparams sufficient}
\end{equation}
Since $R_C$ essentially scales with the largest degree of $G$ (see Eq.\ref{eq : estimate R_C metaparameters}) we only expect systems with a low connectance food consumption adjacency matrix to be able to achieve an LRI state.

This allows to give a necessary condition on the magnitude of $\alpha_0$. Indeed, since the RHS of the previous equation is negative, we need:
\begin{equation}
\alpha_0 O_{\mu \mu}-\gamma_0 R_0 C_{\mu\mu} < 0 \ \forall \mu \implies {\alpha_0 \max_\mu \left\{ \frac{O_{\mu\mu}}{C_{\mu\mu}}  \right\} < \gamma_0 R_0 .} \label{eq : LRI necessary maximum alpha0}
\end{equation}
It is clear that systems with the maximal ratio of $O_{\mu\mu}$ and $C_{\mu\mu}$ is small will be more easily into a LRI regime. The most favoured systems will be those where $S_{\mu\mu}=0 \ \forall \mu$, \ie systems where no species consumes what it itself produces. In that way we may say that coprophagy tends to destabilize microbial communities.
Combining Eq.\eqref{eq : feasability positivity m} and \eqref{eq : LRI necessary maximum alpha0} gives us a necessary condition on $\alpha_0$ for feasible systems (need more details?):
\begin{equation}
\boxed{
\alpha_0 \left[\max_\mu \left\{O_{\mu\mu}\right\}-\min_\mu \left\{ \frac{k^\alpha_\mu}{k^\gamma_\mu} \right\} \right] \leq \frac{l_0}{\min_\mu\left(k_\mu^\gamma\right)S_0}}.
\end{equation}
Although that equation gives us a necessary condition, it is not sufficient. Eq.\eqref{eq : LRI metaparams sufficient}, on the other hand, is and provides an intuitive way of finding a syntrophy adjacency matrix $A_{\mu i}$ that would put a system with a given consumption adjacency $G_{\mu i}$ in an LRI regime. Section \ref{section : numerical analysis LRI MC solver} explains in details how this can be achieved numerically.

\subsubsection{Monte Carlo algorithm for the optimal syntrophy matrix} \label{section : numerical analysis LRI MC solver}
We want to find a general algorithm which, for a given food consumption adjacency matrix $G$ gives back an optimal syntrophy adjacency matrix $A$. Strategically, we would like an $A$ such that Eq.\eqref{eq : LRI metaparams sufficient} is as close to being satisfied as possible. If it were satisfied, it would put the system in an LRI regime, which we have proven is dynamically stable.

One way of trying to satisfy Eq.\eqref{eq : LRI metaparams sufficient} is to increase the magnitude of its LHS and minimize the magnitude of the RHS. The LHS is minimized if $(AG)_{\mu\mu}$ is set to its lowest possible value for every $\mu$, that is zero. On the other hand, the RHS is minimized if $\alpha_0(AG)_{\mu\nu}\approx\gamma_0R_0 (G^TG)_{\mu\nu} \ \forall \nu\neq\mu$.

Intuitively, we then search for systems where $AG$ is zero on the diagonal, \ie where no coprophagy is observed, and $AG \approx \frac{\gamma_0R_0}{\alpha_0}G^TG$ outside the diagonal. It can be formalized by writing a proper Metropolis-Hastings Markov Chain Monte Carlo (MCMC) method. We designed the following algorithmic procedure to build a syntrophy adjacency matrix $A$:
\begin{enumerate}
\item Create a random $A$. Its connectance is chosen as the one of the consumption matrix $G$.
\item Do the following for a given number of steps:
\begin{itemize}
\item Choose a random row or, every other iteration, a column.
\item In that row/column, try to swap a zero and a one while preserving the ``releasers'': if a species releases some resource, it has to keep releasing something (the resource can change though). The ``releasees'' are preserved as well : if a resource is being released by some species, it has to keep being released (but it does not have to be by the same species). \textbf{why do we impose those conditions?}
\item The swap is accepted, \ie $A$ is modified, if the energy difference $\Delta E$ is negative or if a random number drawn uniformly between zero and one is smaller than $e^{-\Delta E/T}$ where $T$ is the current temperature. More on $\Delta E$ and $T$ below.
\end{itemize}
\item Return $A$.
\end{enumerate}
A couple comments on this algorithm can be made:
\begin{itemize}
\item The algorithm preserves the connectance of $A$ but not its nestedness. The question of what value to choose is open, but we choose $\kappa(A)=\kappa(G)$ as a first approach, \ie syntrophy and consumption networks have the same connectance.
\item The temperature $T$ changes dynamically during the simulation. It is obtained in a way close to the spirit of simulated annealing techniques \cite{gendreau_simulated_2019} : the temperature $T$ is multiplied by a factor $\lambda=0.99$ at a fixed frequency (for instance every 1000 steps). We add the requirement that if new moves are rejected during too many consecutive steps, we multiply the temperature by $1/\lambda$.
\item The energy difference $\Delta E$ between the new proposed $A'$ and the old $A$ is computed by assigning an energy $E$ to both $A'$ and $A$ and subtracting them:
\begin{equation}
\Delta E \defined E(A')-E(A).
\end{equation}
The choice of the energy function $E$ is crucial. In essence, this MCMC algorithm will find the specific $A$ which minimizes $E(A)$. Since we want to work with systems in the LRI regime, we use the simplest and most natural function that is compatible with the intuitively expected characteristics of $A$ explained above (\ie $AG$ is zero on the diagonal and equal to $\frac{\gamma_0 R_0}{\alpha_0} G^TG$ outside of it):
\begin{equation}
E(A) \defined \sum_\mu \left( \abs{\alpha_0(AG)_{\mu\mu}} + \sum_{\nu\neq\mu} \abs{(\alpha_0 AG-\gamma_0 R_0 G^TG)_{\mu\nu} }\right).
\end{equation}
The energy function and hence the optimal syntrophy adjacency matrix $A$ depend on the ratio $\frac{\alpha_0}{\gamma_0 R_0}$. This prompts then the question of which $\alpha_0$ can be deemed sensible. As a first step, we will take the value of Eq.\eqref{eq : largest feasible alpha0} : $\alpha_0 = \min(1-\sigma_0, \sigma_0) \gamma_0 R_0 N_R$. This means that the outcome of the algorithm is an optimized $A$ \textbf{for the largest feasible syntrophy}. Since the expression we have for the largest feasible syntrophy is independent of the $G$ matrix, this choice of $\alpha_0$ provides us a sensible way of comparing different consumption networks.
\end{itemize}



% \paragraph{LRI state for an identity food consumption matrix}
% We would like to know which systems can be in an LRI regime. Consider here the case of $N_R=N_S$ and every species consumes exactly one resource, to each its own. This means the food consumption adjacency matrix is precisely the identity matrix :
% \begin{equation}
% G_{i\mu} = \delta_{i\mu}.
% \end{equation}
% We can then compute explicitly the $\Gamma\Beta$ matrix :
% \begin{equation}
% \left(\Gamma \Beta\right)_{\mu \nu} = \sum_i \left(\alpha_{\mu i}- \gamma_{i\mu}R_\mu^*\right) \sigma_{i\nu}\gamma_{i\nu}S_i^*=\delta_{\mu\nu}\left(\alpha_{\mu\nu}-\gamma_{\nu\mu}R_\mu^*\right)\sigma_{\mu\nu}\gamma_{\mu\nu}S_\nu^*.
% \end{equation}
% Also,
% \begin{equation}
% \sum_\nu \abs{B_{i\nu}} = \sum_\nu \sigma_{i\nu}\gamma_{i\nu} S_i^* = \sigma_{\nu\nu}\gamma_{\nu\nu}S^*_\nu,
% \end{equation}
% and
% \begin{equation}
% \sum_j \abs{\Gamma_{\mu j}}= \abs{\Gamma_{\mu\mu}}=\abs{\alpha_{\mu\mu}-\gamma_{\mu\mu}R^*_\mu}\sigma_{\mu\mu}\gamma_{\mu\mu}S^*_\mu,
% \end{equation}
% such that
% \begin{equation}
% R_C = \max\left(\max_\mu\left\{\sigma_{\mu\mu}\gamma_{\mu\mu}S^*_\mu\right\}, \max_\mu \left\{\abs{\alpha_{\mu\mu}-\gamma_{\mu\mu}R^*_\mu}\sigma_{\mu\mu}\gamma_{\mu\mu}S^*_\mu\right\}\right).
% \end{equation}
% Then we have clearly :
% \begin{empheq}{align}
% (\Gamma\Beta)_{\mu\mu} = \left(\alpha_{\mu\mu}-\gamma_{\mu\mu}R_\mu^*\right)\sigma_{\mu\mu}\gamma_{\mu\mu}S_\mu^*
% \end{empheq}
\subsection{Effective system}
Models which involve the dynamics of species only are in general better known than consumers-resources models [\textbf{insert reference}]. In particular, a huge body of literature exists on the study of Lotka-Volterra systems [\textbf{insert reference}]. We may profit from this knowledge by transforming the effect of the resources dynamics into an effective consumers-only system.

This can be done by assuming that the resources reach an equilibrium way faster than the consumers.
Mathematically, that is equivalent to
\begin{equation}
  \frac{dR_\mu}{dt} \approx 0, \\ \forall \mu.
\end{equation}
Using Eq.\eqref{eq : differential eq for resources}, we get an explicit value for the resources:
\begin{equation}
  R_\mu \approx \frac{l_\mu+\sum_j \alpha_{\mu j}S_j}{m_\mu + \sum_k \gamma_{k\mu}S_k}.
\end{equation}
This expression can be used in Eq.\eqref{eq : differential eq for species} to get an effective system which describes the dynamics of the $N_S$ consumers :
\begin{equation}
  \frac{dS_i}{dt} = \left(\sum_\nu \left(\frac{\sigma_{i\nu}\gamma_{i\nu}l_\nu}{m_\nu+\sum_k \gamma_{k\nu}S_k} - \alpha_{\nu i}\right) -d_i + \sum_{\nu j} \frac{\sigma_{i\nu}\gamma_{i\nu}\alpha_{\nu j}}{m_\nu+\sum_{k}\gamma_{k\nu}S_k}S_j \right) S_i.
\end{equation}
This can be rewritten in a more compact way:
\begin{equation}
  \frac{dS_i}{dt} = p_i(S) S_i + \sum_j M_{ij}(S)S_i S_j \label{eq : effective equations of evolution}
\end{equation}
with
\begin{equation}
    p_i(S) = -\left(d_i+\sum_{\nu}\alpha_{\nu i}\right) + \sum_\nu \frac{\sigma_{i\nu}\gamma_{i\nu}l_\nu}{m_\nu+\sum_k \gamma_{k\nu}S_k}\text{ and } M_{ij}(S)=\sum_{\nu}\frac{\sigma_{i\nu}\gamma_{i\nu}\alpha_{\nu j}}{m_\nu+\sum_{k}\gamma_{k\nu}S_k}.
\end{equation}
If we assume the species $S_k$ are not too far away from their equilibrium values\footnote{Note that this is very rarely true, especially in the context of the study of structural stability, where entire species sometimes die out.}, \ie
\begin{equation}
S_k \approx S^*_k \ \forall k,
\end{equation}
then using Eq.\eqref{eq : positive m_nu} we can simplify $p_i$. Indeed,
\begin{equation}
m_\nu + \sum_k \gamma_{k\nu} S_k \approx m_\nu + \sum_k \gamma_{k\nu}S^*_k = \frac{l_\nu + \sum_k \alpha_{\nu k}S^*_k}{R^*_\nu} \label{eq : equality fluxes resource}
\end{equation}
Hence, the explicit dynamical dependence on $S$ can be removed from $p_i$ and $M_{ij}$:
\begin{equation}
p_i(S) \approx p_i \equiv - \left(d_i + \sum_\nu \alpha_{\nu i}\right) + \sum_\nu \frac{\sigma_{i\nu}\gamma_{i\nu}l_\nu R^*_\nu}{l_\nu + \sum_k \alpha_{\nu k}S^*_k},
\end{equation} and
\begin{equation}
M_{ij}(S) \approx M_{ij} \equiv \sum_\nu \frac{\sigma_{i\nu} \gamma_{i\nu} R^*_\nu \alpha_{\nu j}}{l_\nu + \sum_k{\alpha_{\nu k} S^*_k}}.
\end{equation}
\subsubsection{Perturbation analysis}
We study a system that we put close to an equilibrium $S^*$, \ie
\begin{equation}
S=S^*+\Delta S, \\ \text{with } \Delta S \ll 1.
\end{equation}
Written this way, the effective equations of motion Eq.\eqref{eq : effective equations of evolution} are equivalent to:
\begin{equation}
\frac{d\Delta S_i}{dt} = p_i(S^*+\Delta S)\left(S^*_i + \Delta S_i\right)+\sum_j M_{ij}(S^*+\Delta S)\left(S^*_i +\Delta S_i\right)\left(S^*_j +\Delta S_j\right).
\end{equation}
Since the deviations from equilibrium $\Delta S_i \ll 1$, we can forget the terms in higher power than quadratic:
\begin{equation}
\frac{d\Delta S_i}{dt} = \tilde{p}_i \Delta S_i + \sum_j E_{ij} \Delta S_j + \bigO(\Delta S^2),\label{eq : effective equ evol at O(D2)}
\end{equation}
with
\begin{equation}
\tilde{p}_i \equiv p_i(S^*) + \sum_k M_{ik}(S^*)S_k^*, \label{eq : tilde p effective system}
\end{equation}
and
\begin{equation}
E_{ij} \equiv \left(\partiald{p_i}{S_j}\evaluatedat{S^*}+M_{ij}(S^*)+\sum_k \partiald{M_{ik}}{S_j}\evaluatedat{S^*}S^*_k\right)S^*_i.
\end{equation}
After some computations, we can get $\tilde{p}_i$ and $E_{ij}$ in terms of the initial parameters. Indeed,
\begin{equation}
p_i(S^*)= -\left(d_i + \sum_\nu \alpha_{\nu i}\right) + \sum_\nu \frac{\sigma_{i\nu}\gamma_{i\nu}l_\nu}{m_\nu + \sum_k \gamma_{k\nu}S^*_k}
\end{equation}
and
\begin{equation}
M_{ik}(S^*) = \sum_\nu \frac{\sigma_{i\nu}\gamma_{i\nu}\alpha_{\nu j}}{m_\nu + \sum_k \gamma_{k\nu}S^*_k}.
\end{equation}
Hence, using Eq.\eqref{eq : tilde p effective system} :
\begin{equation}
\tilde{p}_i = - \left(d_i + \sum_\nu \alpha_{\nu i}\right) + \sum_\nu \frac{\sigma_{i\nu}\gamma_{i\nu}}{m_\nu + \sum_k \gamma_{k\nu}S^*_k}\left(l_\nu+\sum_{j}\alpha_{\nu j} S^*_j\right).
\end{equation}
This can be simplified using Eq.\eqref{eq : equality fluxes resource} and Eq.\eqref{eq : equilibrium species} :
\begin{equation}
\tilde{p}_i=-d_i +\sum_\nu \sigma_{i\nu}\gamma_{i\nu}R^*_\nu = \sum_\nu \alpha_{\nu i}.
\end{equation}
With a similar computation, one finds
\begin{equation}
E_{ij}=\sum_\nu \frac{\sigma_{i\nu}\gamma_{i\nu}S^*_i}{m_\nu+\sum_k \gamma_{k\nu}S^*_k} \left(\alpha_{\nu j}-\gamma_{j\nu}R^*_\nu\right).
\end{equation}
Finally, Eq.\eqref{eq : effective equ evol at O(D2)} can be recast in
\begin{equation}
\frac{d\Delta S_i}{dt} = \sum_j (J_E)_{ij} \Delta S_j,
\end{equation}
where the effective $N_S\times N_S$ jacobian matrix $J_E$ is defined by:
\begin{equation}
(J_E)_{ij}=\sum_\nu \left[\frac{\sigma_{i\nu}\gamma_{i\nu}S^*_i}{m_\nu+\sum_k \gamma_{k\nu}S^*_k} \left(\alpha_{\nu j}-\gamma_{j\nu}R^*_\nu\right)+\alpha_{\nu i}\delta_{ij}\right].
\end{equation}
We see that we without surprise we find again the $\Beta, \Gamma $ and $\Delta$ matrices coming from the jacobian at equilibrium :
\begin{equation}
\left(J_E\right)_{ij}=\sum_\nu \left[\frac{\Beta_{i\nu}\Gamma_{\nu j}}{\Delta_\nu}+\alpha_{\nu i} \delta_{ij}\right]
\end{equation}

This matrix determines the stability of the equilibrium. Namely if the largest eigenvalue of $J_E$ is positive, the equilibrium is unstable. If it is negative, the equilibrium is stable. If it is zero, the equilibrium is marginal.



\subsection{Identifying the order parameter}
\subsubsection{Flux analysis}
A natural scale free order parameter that at first sight controls the behaviour of the system is the ratio of the syntrophy and consumption fluxes.

The rate of consumption (or \textit{consumption flux}) of species $i$ is given by $\sum_\nu \sigma_{i\nu}\gamma_{i\nu}R_\nu S_i$. Hence the total consumption flux $C_{\text{tot}}$ is given by :
\begin{equation}
C_{\text{tot}} = \sum_{i, \nu} \sigma_{i\nu} \gamma_{i\nu}R_\nu S_i.
\end{equation}
We can similarly define the total syntrophy flux of the system $S_{\text{tot}}$ :
\begin{equation}
S_{\text{tot}} = \sum_{i, \nu} \alpha_{\nu i} S_i.
\end{equation}
A natural order parameter $O$ is then
\begin{equation}
O \equiv \frac{S_{\text{tot}}}{C_{\text{tot}}} = \frac{\sum_{i, \nu} \alpha_{\nu i} S_i}{\sum_{i,\nu}\sigma_{i\nu} \gamma_{i\nu}R_\nu S_i} \approx \frac{N_S N_R \alpha_0 S_0}{\sigma_0 R_0 S_0 N_S N_R \gamma_0} = \frac{\alpha_0}{\sigma_0 R_0 \gamma_0}.
\end{equation}



\end{document}
