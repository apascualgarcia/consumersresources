\documentclass[12pt, titlepage]{report}
\usepackage{consumer_resource_final}
\graphicspath{{./figures/}}

\begin{document}


% We want to be able to build feasible models numerically, \ie we would like to generate a set of constant numbers $\{
% l_\nu, m_\nu, R^*_\nu, S^*_j, \gamma_{j\nu}, \alpha_{\nu j}, \sigma_{j\nu}\}$ such that the equilibria equations Eqs.\eqref{eq : equilibrium resources and species} are fulfilled.
%\subsection{The feasibility region} \label{sec : methods feasibility volume}
%\subsubsection{The feasibility region}

%As soon as $\gamma_0$ and $S_0$ are chosen, we get a range of $\alpha_0$ which gives rise to feasible systems.
%We will then choose $\gamma_0$ and $S_0$ such that they lead to feasible systems for every consumption matrix considered here \textbf{when there is no syntrophy}, \ie $\alpha_0=0$. We will then study the impact of varying $\alpha_0$ at those values of $\gamma_0$ and $S_0$.





% \paragraph{Energy conservation/dissipation}
% The first condition we will impose on our systems is that they do not create new matter.
%
% Remember that in our model, the total amount of biomass given to the species $i$ by the resources is $\sum_\nu \gamma_{i\nu}R_\nu S_i$.
% However species $i$ will not allocate all of this biomass to growth. As seen in Eq.\eqref{eq : differential eq for species}, only a fraction $\sigma_{i\nu}$ will be used in this purpose. This means species $i$ disposes of $\sum_\nu(1-\sigma_{i\mu})\gamma_{i\mu}R_\mu S_i$ biomass to complete other processes.
% We know that one of these is producing byproducts (\ie the syntrophic interaction) at a total rate $\sum_\nu \alpha_{\nu i} S_i$. Because this biomass is produced in the cell, it has to come from the biomass the cell disposes of, which naturally leads to the condition\footnote{Note that the condition is a bit relaxed here. Biomass cannot be created at equilibrium. However we allow some transient regimes where this momentarily can occur, \eg after a big shock inflicted to the system.}:
%   \begin{equation}
%   \sum_{\nu} \left(1-\sigma_{i\nu}\right)\gamma_{i\nu}R^*_\nu \geq \sum_\nu \alpha_{\nu i} \label{eq : dissipation constraint}
% \end{equation}
% The above equation will be referred to as the \textit{conservation of biomass constraint}.
%
% The idea is to find metaparameters such that this constraint is automatically satisfied (which eases building the system numerically). This is easily done by finding the minimum of the LHS and maximum of RHS of Eq.\eqref{eq : dissipation constraint}. Indeed :
% \begin{equation}
%   \sum_{\nu} \left(1-\sigma_{i\nu}\right)\gamma_{i\nu}R^*_\nu \geq (1-\maxd{\sigma})\mind{\gamma}\mind{R^*},
% \end{equation}
% where \ $\mind{ }$ \ denotes the minimum value of the random variable and \ $\maxd{ }$ \ its maximum value. On the other hand,
% \begin{equation}
%   \sum_\nu \alpha_{\nu i} \leq \maxd{\alpha} N_R.
% \end{equation}
% This means that if we take metaparameters such that
% \begin{equation}
%   \maxd{\alpha} N_R < (1-\maxd{\sigma})\mind{\gamma}\mind{R^*}, \label{eq : min and max energy constraint}
% \end{equation}
% then Eq.\eqref{eq : dissipation constraint} is automatically followed.
%
% Because of the way we choose our variables we have for every random variable in the problem,
% \begin{equation}
% \mind{X} = (1-\epsilon)\mean{X} \text{ and }\maxd{X} = (1+\epsilon)\mean{X}
% \end{equation}
% where \ $\mean{X}$ \ denotes the mean of $X$. This means Eq.\eqref{eq : min and max energy constraint} is equivalent to, in terms of metaparameters:
% \begin{equation}
%   \alpha_0 < \frac{\left(1-\epsilon\right)^2}{1+\epsilon}\left(1-\left(1+\epsilon\right)\sigma_0\right)\frac{\gamma_0 R_0}{N_R}.
% \end{equation}
% In the $\epsilon \ll 1$ limit, this is equivalent to:
% \begin{equation}
%   \alpha_0 < \left(1-3\epsilon\right)\left(1-(1+\epsilon)\sigma_0\right)\frac{\gamma_0 R_0}{N_R}.
% \end{equation}
% % \begin{equation}
% %   \sum_{\nu} \left(1-\sigma_{i\nu}\right)\gamma_{i\nu}R^*_\nu \geq \min_\nu\left(\left(1-\sigma_{i\nu}\right)R^*_\nu\right) \sum_\nu \gamma_{i\nu} \geq \left(1-\max_\nu\left(\sigma_{i\nu}\right)\right)\min_\nu\left(R^*_\nu\right)N_R \gamma_0.
% % \end{equation}
% % Now, the way we draw the $\sigma_{i\nu}$ numerically is effectively by drawing elements of a uniform distribution of mean $\sigma_0$, i.e.
% % \begin{equation}
% %   \sigma_{i\nu} \approx \text{Unif}(0, 2\sigma_0).
% % \end{equation}
% % It is quite easy to estimate $\max_\nu(\sigma_{i\nu})$, indeed we can easily show that :
% % \begin{equation}
% %   E\left[\max_\nu\left(\sigma_{i\nu}\right)\right] = 2 \sigma_0 \frac{N_R}{N_R+1}.
% % \end{equation}
% % This has a standard deviation
% % \begin{equation}
% %   \tilde{\sigma} = \frac{2 \sigma_0}{N_R+1}\sqrt{\frac{N_R}{N_R+2}}.
% % \end{equation}
% % Similarly one can show that if
% % \begin{equation}
% %   R^*_\nu \approx \text{Unif}(0,2R_0),
% % \end{equation}
% % then
% % \begin{equation}
% %   E\left[\min_\nu \left(R^*_\nu\right)\right]  = \frac{2R_0}{N_R+1}.
% % \end{equation}
% % Then we can estimate
% % \begin{equation}
% %   \left(1-\max_\nu\left(\sigma_{i\nu}\right)\right)\min_\nu\left(R^*_\nu\right)N_R \gamma_0 \approx 2R_0\gamma_0\left(1-2\sigma_0 \frac{N_R}{N_R+1}\right)\frac{N_R}{N_R+1}
% % \end{equation}
% % We now find an upperbound for the RHS of Eq.\eqref{eq : dissipation constraint} :
% % \begin{equation}
% %   \sum_\nu \alpha_{\nu i}  \leq \sum_\nu \max_\nu\left(\alpha_{\nu i}\right) \approx 2\alpha_0 \frac{N_R}{N_R+1} N_R.
% % \end{equation}
% % This means that if we pick metaparameters verifying :
% % \begin{equation}
% %   R_0 \gamma_0 \left(1-2\sigma_0\frac{N_R}{N_R+1}\right) \gg \alpha_0 N_R.
% % \end{equation}
% % In the $N_R \gg 1$ limit :
% % \begin{equation}
% %   \frac{\gamma_0}{\alpha_0} \gg \frac{N_R}{R_0(1-2\sigma_0)}.
% % \end{equation}
% % This condition allows us to pick metaparameters that we know will satisfy the energy constraint most of the time. This is done solely to speed up computation time (energy constraint is checked anyway while building the system).
%
% \paragraph{Positivity of the parameters}
% Feasability means at least that every physical parameter defined here must be positive. In particular, this implies:
% \begin{equation}
%   d_i > 0 \implies \sum_\mu \sigma_{i\mu}\gamma_{i\mu}R^*_\mu > \sum_\mu \tau_{\mu i}
% \end{equation}
% If $\tau_{i\mu} = 0.$ this is trivially satisfied because $\sigma_{i\mu}$, $\gamma_{i\mu}$ and $R^*_\mu$ have all been drawn positive. However if $\tau_{\mu i} = \alpha_{\mu i}$ this is not always the case and we have to get parameters satisfying :
% \begin{equation}
%   \sum_\mu \sigma_{i \mu} \gamma_{i\mu}R^*_\mu > \sum_{\mu} \alpha_{\mu i}\text{ }\forall i.
% \end{equation}
% We can try to estimate the value of some metaparameters that would satisfy this.
% We have :
% \begin{equation}
%   \sum_\mu \sigma_{i\mu} \gamma_{i\mu} R^*_\mu \geq \mind{\sigma}\mind{\gamma}\mind{R^*}.
% \end{equation}
% Using this boundary and Eq.\eqref{eq : min and max energy constraint}, we know that $d_i>0$ if
% \begin{equation}
%   \maxd{\alpha}N_R \leq \mind{\sigma} \mind{\gamma}\mind{R^*},
% \end{equation}
% \ie
% \begin{equation}
%   \alpha_0 < \frac{\left(1-\epsilon\right)^3}{1+\epsilon} \frac{\sigma_0 \gamma_0 R_0}{N_R},
% \end{equation}
% or in the $\epsilon \ll 1$ limit :
% \begin{equation}
%   \alpha_0 < \left(1-4\epsilon\right)\frac{\sigma_0 \gamma_0 R_0}{N_R}.
% \end{equation}
% Similarly we must have a positive death rate for the resources, \ie:
% \begin{equation}
%   m_\nu = \frac{l_\nu-\sum_j \gamma_{j\nu} R^*_\nu S^*_j+\sum_j \alpha_{\nu j} S^*_j}{R^*_\nu} > 0. \label{eq : positive m_nu}
% \end{equation}
% This means we have to impose parameters that verify:
% \begin{equation}
%   l_\nu + \sum_j \alpha_{\nu j}S^*_j > \sum_j \gamma_{j \nu}R^*_\nu S^*_j.
% \end{equation}
% We can do a reasoning similar to before, \ie find a lower boundary for the LHS and an upper boundary for the RHS.
% We have
% \begin{equation}
%   l_\nu + \sum_{j} \alpha_{\nu j} S^*_j \geq \mind{l} + \mind{\alpha} \mind{S^*}
% \end{equation}
% and
% \begin{equation}
%   \sum_j \gamma_{j\nu}R^*_\nu S^*_j \leq N_S \maxd{\gamma}\maxd{R^*}\maxd{S^*}.
% \end{equation}
% Hence if we get parameters satisfying
% \begin{equation}
%   \mind{l}+\mind{\alpha}\mind{S^*} > N_S \maxd{\gamma}\maxd{R^*}\maxd{S^*},
% \end{equation}
% then Eq.\eqref{eq : positive m_nu} will be immediately satisfied. In terms of metaparameters this is equivalent to:
% \begin{equation}
%   \alpha_0 > \frac{N_S \gamma_0 R_0 S_0 (1+\epsilon)^3-l_0 (1-\epsilon)}{S_0 (1-\epsilon)^2}.\label{eq : alpha lowerbound 0}
% \end{equation}
% In the $\epsilon \ll 1$ limit this is equivalent to:
% \begin{equation}
%   \alpha_0 > \left(1+5\epsilon\right)N_S \gamma_0 R_0 - \left(1+\epsilon\right)\frac{l_0}{S_0}.
% \end{equation}
% (Interesting, if $l_0/S_0$ is large enough, \ie "there is enough food for everyone" then this condition is irrelevant).
% % Indeed,
% % \begin{equation}
% %   \sum_\mu \alpha_{\mu i} \leq \sum_\mu \max_\mu \left(\alpha_{\mu i}\right) \approx 2\alpha_0 \frac{N_R}{N_R+1} N_R \text{
% %     (see above).
% %   }
% % \end{equation}
% % Similarly,
% % \begin{equation}
% %   \sum_{\mu} \sigma_{i\mu}\gamma_{i\mu}R^*_\mu \geq \min_\mu\left(\sigma_{i\mu}R^*_\mu\right)\sum_\mu \gamma_{i\mu} \geq \min_\mu\left(\sigma_{i\mu}\right)\min_\mu\left(R^*_\mu\right) N_R \gamma_0.
% % \end{equation}
% % Using the estimations for $\min_\mu\left(\sigma_{i\mu}\right)$ and $\min_\mu\left(R^*_\mu\right)$ :
% %  \begin{equation}
% %    \min_\mu\left(\sigma_{i\mu}\right) \approx E\left[\min_\mu\left(\sigma_{i\mu}\right)\right] = \frac{2 \sigma_0}{N_R+1}\text{, }\min_\mu\left(R^*_\mu\right) \approx E\left[\min_\mu\left(R^*_\mu \right)\right] = \frac{2 R_0}{N_R+1}
% %  \end{equation}
% %  This means we have to take :
% %  \begin{equation}
% %    \frac{\gamma_0}{\alpha_0} \gg \frac{N_R(N_R+1)}{2\sigma_0 R_0}.
% %  \end{equation}
%
% \paragraph{Combining conditions}
% If we combine both upperbounds we get a restriction on the metaparameters:
% % \begin{equation}
% %   \frac{\gamma_0}{\alpha_0} \gg \max\left(\frac{N_R(N_R+1)}{2\sigma_0 R_0}, \frac{N_R}{R_0(1-2\sigma_0)}\right)
% % \end{equation}
% % To get an idea on the order of magnitude of the ratio $\gamma_0/\alpha_0$ (\ie our order parameter), if we work with $N_R = 25$, $\sigma_0 = 0.2$, $R_0 = 1$, we have
% % \begin{equation}
% %   \frac{N_R(N_R+1)}{2\sigma_0 R_0} = 1'625 \text{ and } \frac{N_R}{R_0(1-2\sigma_0)} \approx 42
% % \end{equation}
% % \ie we will need, if $\gamma_0 \approx 1$
% % \begin{equation}
% %   \alpha_0 \ll 6.1 \times 10^{-4}.
% % \end{equation}
% % That means only very small metabolite release (this is indeed what we observe numerically).
% \begin{subequations}\label{eq : alpha bounds}
% \begin{equation}
% \alpha_0 < \min\left(\frac{\left(1-\epsilon\right)^2}{1+\epsilon}\left(1-\left(1+\epsilon\right)\sigma_0\right)\frac{\gamma_0 R_0}{N_R}, \frac{\left(1-\epsilon\right)^3}{1+\epsilon} \frac{\sigma_0 \gamma_0 R_0}{N_R}\right). \label{eq : alpha upperbound}
% \end{equation}
% We of course also get a restriction on the lowerbound of $\alpha_0$ through Eq.\eqref{eq : alpha lowerbound 0}:
% \begin{equation}
%   \alpha_0 > \frac{N_S \gamma_0 R_0 S_0 (1+\epsilon)^3-l_0 (1-\epsilon)}{S_0 (1-\epsilon)^2}. \label{eq : alpha lowerbound}
% \end{equation}
% \end{subequations}
% To get an idea on the order of magnitude of $\alpha_0$ (which will be our order parameter if $\gamma_0=1$), we have for $N_R=25$, $\sigma_0 = 0.2$, $R_0 = 1$ and $\epsilon=0.1$ :
% \begin{equation}
%   \alpha_0 < 5.3 \times 10^{-3}.
% \end{equation}
% So what we see in Eq.\eqref{eq : alpha upperbound} is that $\alpha_0$ has an upper bound which is dictated either by energy conservation or system feasability. What relations do the metaparameters have to fulfill in these two different regimes?
%
% Suppose that the limiting factor is system feasability. That means:
% \begin{empheq}{align}
%    \frac{\left(1-\epsilon\right)^3}{1+\epsilon} \frac{\sigma_0 \gamma_0 R_0}{N_R} &\leq \frac{\left(1-\epsilon\right)^2}{1+\epsilon}\left(1-\left(1+\epsilon\right)\sigma_0\right)\frac{\gamma_0 R_0}{N_R} \nonumber \\
%   \iff  (1-\epsilon) \sigma_0 &\leq 1-(1+\epsilon)\sigma_0 \nonumber\\
%   \iff \sigma_0 &\leq \frac{1}{2}
% \end{empheq}
% This means if $\sigma_0 \leq \frac{1}{2}$, the limiting factor will be system feasability while if $\sigma_0 \geq \frac{1}{2}$, it will be energy conservation.
\subsection{Building feasible systems}\label{sec : feasibility methods algorithmic procedure}
We hereby detail the $\mathcal{A}$ procedure which from a set of metaparameters $m$ and a consumption-syntrophy network $(G,A)$ gives rise to a set of parameters $p$. It goes like this:
\begin{enumerate}
  \item We first randomly draw each $R^*_\nu$
  and $S^*_i$ :
  \begin{equation}
     R^*_\nu = \mathcal{R} \ \forall \nu=1, \dots, N_R\text{ and }  S^*_i = \mathcal{S} \ \forall i=1, \dots, N_S,
  \end{equation}
  where $\mathcal{R}$ and $\mathcal{S}$ are random variables coming from a distribution of mean equal to the corresponding metaparameter and relative standard deviation\footnote{By relative standard deviation, we mean the standard deviation measured in units of the average value.} $\epsilon$. In our simulations, we choose uniform distributions :
  \begin{equation}
  \mathcal{R} \sim \text{Unif}(R_0, R_0 \epsilon) \text{ and } \mathcal{S} \sim \text{Unif}(S_0, S_0\epsilon).
  \end{equation}
  \item The efficiency matrix $\sigma_{i\nu}$ is then drawn similarly, from a distribution with average $\sigma_0$. In order to simplify the problem\footnote{Indeed we observed that in general introducing a non uniform $\sigma_{i\mu}$ adds an unnecessary additional layer of complexity, which we would like to avoid.}, we take a zero-variance like \citeauthor{butler_stability_2018} in \cite{butler_stability_2018}, \ie all species consume resources at the same global efficiency:
  \begin{equation}
    \sigma_{i\nu} = \sigma_0.
  \end{equation}
  \item We build the consumption matrix $\gamma_{i\nu}$. Its adjacency matrix $G$ is loaded through a user-provided file.
  %$G$ is a binary matrix given by the user (in the \code{configuration.in} file) and is defined as the adjacency matrix of the consumption network (\ie it tells which species eats which resource). We then build $\gamma$ with the same network structure as $F$ (\ie both matrices have the same zero elements).
  While $G$ gives the structure of $\gamma$, \ie if a given $\gamma_{i\nu}$ is zero or not, the actual values of $\gamma_{i\nu}$ need then to be determined. They are drawn from a uniform distribution of mean $\gamma_0$ and relative standard deviation $\epsilon$:
  \begin{equation}
    \gamma_{i\nu} = \text{Unif}(\gamma_0, \gamma_0\epsilon) G_{i\nu}.
  \end{equation}
  \item We draw the resources external feeding rates, similarly to the other parameters:
  \begin{equation}
  l_\mu = \text{Unif}(l_0, l_0\epsilon) \ \forall \mu=1, \dots, N_R.
  \end{equation}
  \item The last free parameters are the non-zero elements of the syntrophy matrix $\alpha_{\nu i}$, since the $d_i$ and $l_\mu$ are determined through the equations of evolution at equilibrium. %This is the tricky part of the algorithm because $\alpha$ has to follow three constraints, namely energy conservation/dissipation Eq.\eqref{eq : dissipation constraint} and positiveness of $d_i$ and $l_\mu$ [\textbf{insert reference to equation}]. The general strategy is to choose the metaparameters in a way that these constraints should \textit{almost always} be satisfied, \ie we pick metaparameters that follow the feasibility constraint Eq.\eqref{eq : overall feasibility constraint metaparameters}.
  The adjacency matrix $A$ of $\alpha$ needs then to be specified. The user can either choose one of the scenarios above (Section \ref{sec: syntrophy scenarios}) or provide directly a matrix with the right dimensions. After the adjacency matrix is loaded, we build $\alpha$ from a uniform distribution of mean $\alpha_0$ and relative standard deviation $\epsilon$:
  \begin{equation}
    \alpha_{\nu i} = \text{Unif}(\alpha_0, \alpha_0\epsilon) A_{\nu i} .
  \end{equation}
  %\item We build $\tau_{\nu i}$. It usually is equal to $\alpha_{\nu i}$ or 0.
  \item With all of these parameters drawn, we can solve Eqs.\eqref{eq : feasibility positive d} for the species death rate $d_i$ and Eqs.\eqref{eq : feasibility positive m} for $m_\nu$. All the parameters of the model are now fully determined.
  \item We check if the constraints Eqs.\eqref{eq : feasibility positive d and m} and \eqref{eq : feasability biomass conservation} on the parameters are fulfilled. If they are not, we go back to step 1. Otherwise, a feasible system has been built and the algorithm is successfully exited. We see here the advantage of having input metaparameters that will most likely give rise to a feasible parameter set. If we just give random metaparameters, we run the risk of getting stuck in an unpredictably long loop between steps 1 and 7. If however we are in a region where we know the metaparameters feasibility is high, a feasible system is found much faster.
\end{enumerate}
\end{document}
