\documentclass[12pt]{report}
\usepackage{consumer_resource_final}
\begin{document}
\subsection{Special determinant computation}\label{app : special determinant computation}
We want to know when the determinant of the following $N$-dimensional square matrix is zero:
\begin{equation}
A_N = \begin{pmatrix}
a & b & b  \\
b & \ddots & b  \\
b & b & a
\end{pmatrix}, \ie \ A_{ij} = b+(a-b)\delta_{ij}.
\end{equation}
The equation we want to solve is:
\begin{equation}
\det\left(A_N\right)=0. \label{app: eq: det A_N 0}
\end{equation}
Note that, using Gaussian elimination, Eq.\eqref{app: eq: det A_N 0} can be transformed in:
\begin{equation}
\det\begin{pmatrix}
a & b & \dots & b \\
b-a & a-b & 0 & 0 \\
0 & \ddots & \ddots & 0 \\
0 & 0 & b-a & a-b
\end{pmatrix}=0
\end{equation}
Using Laplace's expansion, this can be written as:
\begin{equation}
 a \det\begin{pmatrix}
a-b & 0 & \dots & 0 \\
b-a & a-b & 0 & 0 \\
0 & \ddots & \ddots & 0 \\
0 & 0 & b-a & a-b
\end{pmatrix}+(a-b)
\det\begin{pmatrix}
b & b & \dots & b \\
b-a & a-b & 0 & 0 \\
0 & \ddots & \ddots & 0 \\
0 & 0 & b-a & a-b
\end{pmatrix}=0 \label{app: eq: laplace expansion}
\end{equation}
Since the first term of the previous equation is a lower triangular matrix, its determinant is easily found:
\begin{equation}
a \det\begin{pmatrix}
a-b & 0 & \dots & 0 \\
b-a & a-b & 0 & 0 \\
0 & \ddots & \ddots & 0 \\
0 & 0 & b-a & a-b
\end{pmatrix} = a\left(a-b\right)^{n-1}.
\end{equation}
Finding an explicit equation for the left term is a bit more involving. Let us define the general $n$ square matrix $F_n(a,b)$:
\begin{equation}
F_n(a,b) = \begin{pmatrix}
b & b & \dots & b \\
b-a & a-b & 0 & 0 \\
0 & \ddots & \ddots & 0 \\
0 & 0 & b-a & a-b
\end{pmatrix}.
\end{equation}
With a Laplace expansion one gets:
\begin{equation}
\det\left(F_n(a,b)\right)= b
\det\begin{pmatrix}
a-b & 0 & 0 \\
b-a & \ddots & 0 \\
0 & b-a & a-b
\end{pmatrix}+(a-b)\det\begin{pmatrix}
b & b & \dots & b \\
b-a & a-b & 0 & 0 \\
0 & \ddots & \ddots & 0 \\
0 & 0 & b-a & a-b
\end{pmatrix}.
\end{equation}
This means:
\begin{equation}
\det(F_n(a,b))=b(a-b)^{n-1}+(a-b)\det(F_{n-1}(a,b)).
\end{equation}
It is easy to check that the solution to the previous equation is:
\begin{equation}
\det(F_n(a,b))=\left[(n-1)b+\det\left(F_1(a,b)\right)\right](a-b)^{n-1}.
\end{equation}
Since $\det\left(F_1(a,b)\right)=1$, we get:
\begin{equation}
\det\left(F_n(a,b)\right)=n(a-b)^{n-1}b
\end{equation}
Inserting this in Eq.\eqref{app: eq: laplace expansion} yields:
\begin{equation}
\boxed{
\det(A_N)=0 \iff (a-b)^{N-1}\left[a+(N-1)b\right]=0.
}\label{eq: formula special determinant}
\end{equation}
\subsection{The optimal $S_0$ for locally dynamically stable systems} \label{sec: appendix how to handle S0}
How $S_0$ should be adjusted is a bit tricky because it is present in three terms that do not have the same behaviour: one term is linear in $S_0$ with a negative coefficient, another is linear with a positive coefficient and another is quadratic (also with a positive coefficient). So we need to compute the minimum value the sum of these three terms is and take $S_0$ as the minimum we found. The consumers equilibrium abundance $S_0^*$ that yields the minimum value is implicitly given by the condition:
\begin{equation}
\frac{d}{dS_0} \left[4N_R \sigma_0 \gamma_0 S_0  (\alpha_0 - \gamma_0 R_0) +\frac{l_0^2}{R_0^2}+\frac{2N_S\alpha_0 S_0 l_0}{R_0^2} + \frac{N_S^2 \alpha_0^2 S_0^2}{R_0^2}\right]_{S_0=S_0^*}=0.
\end{equation}
The enthusiastic reader sees that this is equivalent to:
\begin{equation}
S_0^* = \frac{R_0^2}{N_S^2 \alpha_0^2}\left(2N_R\sigma_0 \gamma_0\left(\gamma_0R_0-\alpha_0\right)-\frac{N_S \alpha_0 l_0}{R_0^2}\right).
\end{equation}
One checks really easily that this point is indeed a minimum in $S_0$. So if $S_0 > S_0^*$ it should be decreased, and otherwise increased. For $\alpha_0 \rightarrow 0$, $S_0^* \rightarrow \infty$, and for $\alpha_0 \rightarrow \infty$, $S_0^* \rightarrow 0^-$, which means we expect to find the most dynamically stable points at large $S_0$ for low syntrophy and at low $S_0$ for large syntrophy.
\end{document}
